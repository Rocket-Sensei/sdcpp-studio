# Models configuration
models:
  # ==================== Qwen Image (Server Mode) ====================
  qwen-image:
    name: "Qwen Image"
    description: "Qwen Image - advanced text-to-image model with complex text rendering and precise image editing capabilities"
    default: true
    capabilities: ["text-to-image"]
    # Server mode command
    command: "./bin/sd-server"
    args:
      - "--diffusion-model"
      - "./models/Qwen_Image-Q4_K_M.gguf"
      - "--vae"
      - "./models/qwen_image_vae.safetensors"
      - "--qwen2vl"
      - "./models/Qwen2.5-VL-7B-Instruct.Q4_K_M.gguf"
      - "-v"
      - "--offload-to-cpu"
      - "--diffusion-fa"
      - "--flow-shift"
      - "3"
    mode: "on_demand"
    exec_mode: "server"
    port: 1400
    model_type: "text-to-image"
    default_size: "1024x1024"
    generation_params:
      cfg_scale: 1.0
      sample_steps: 24
      sampling_method: "euler"
    huggingface:
      repo: "QuantStack/Qwen-Image-GGUF"
      files:
        - path: "Qwen_Image-Q4_K_M.gguf"
          dest: "./models/"
        - path: "qwen_image_vae.safetensors"
          dest: "./models/"
          repo: "Comfy-Org/Qwen-Image_ComfyUI"
          subpath: "split_files/vae"
        - path: "Qwen2.5-VL-7B-Instruct.Q4_K_M.gguf"
          dest: "./models/"
          repo: "mradermacher/Qwen2.5-VL-7B-Instruct-GGUF"
