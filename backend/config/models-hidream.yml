# HiDream Models
models:
  # ==================== HiDream Models (Server Mode) ====================
  # HiDream series with Meta-Llama-3.1-8B-Instruct LLM
  # All HiDream models support negative prompts and use distilled flow matching

  hidream-e1-1:
    name: "HiDream E1.1"
    description: "HiDream E1.1 - Text-to-image model with Llama LLM"
    capabilities: ["text-to-image"]
    supports_negative_prompt: true
    command: "./bin/sd-server"
    args:
      - "--diffusion-model"
      - "./models/HiDream_E1_1_-Q5_1.gguf"
      - "--vae"
      - "./models/ae.safetensors"
      - "--llm"
      - "./models/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      - "-v"
      - "--offload-to-cpu"
      - "--diffusion-fa"
      - "--steps"
      - "20"
    mode: "on_demand"
    exec_mode: "server"
    port: 1529
    model_type: "text-to-image"
    default_size: "1024x1024"
    startup_timeout: 180000
    generation_params:
      cfg_scale: 2.0
      sample_steps: 20
      sampling_method: "euler"

  hidream-i1-dev:
    name: "HiDream I1 Dev"
    description: "HiDream I1 Dev - Development version with NF4 quantization"
    capabilities: ["text-to-image"]
    supports_negative_prompt: true
    command: "./bin/sd-server"
    args:
      - "--diffusion-model"
      - "./models/HiDream-I1-Dev-nf4.safetensors"
      - "--vae"
      - "./models/ae.safetensors"
      - "--llm"
      - "./models/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      - "-v"
      - "--offload-to-cpu"
      - "--diffusion-fa"
      - "--steps"
      - "20"
    mode: "on_demand"
    exec_mode: "server"
    port: 1530
    model_type: "text-to-image"
    default_size: "1024x1024"
    startup_timeout: 180000
    generation_params:
      cfg_scale: 2.0
      sample_steps: 20
      sampling_method: "euler"

  hidream-i1-fast:
    name: "HiDream I1 Fast"
    description: "HiDream I1 Fast - Fast generation variant with NF4 quantization"
    capabilities: ["text-to-image"]
    supports_negative_prompt: true
    command: "./bin/sd-server"
    args:
      - "--diffusion-model"
      - "./models/HiDream-I1-Fast-nf4.safetensors"
      - "--vae"
      - "./models/ae.safetensors"
      - "--llm"
      - "./models/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      - "-v"
      - "--offload-to-cpu"
      - "--diffusion-fa"
      - "--steps"
      - "14"
    mode: "on_demand"
    exec_mode: "server"
    port: 1531
    model_type: "text-to-image"
    default_size: "1024x1024"
    startup_timeout: 180000
    generation_params:
      cfg_scale: 2.0
      sample_steps: 14
      sampling_method: "euler"

  hidream-i1-full:
    name: "HiDream I1 Full"
    description: "HiDream I1 Full - Full quality variant with NF4 quantization"
    capabilities: ["text-to-image"]
    supports_negative_prompt: true
    command: "./bin/sd-server"
    args:
      - "--diffusion-model"
      - "./models/HiDream-I1-Full-nf4.safetensors"
      - "--vae"
      - "./models/ae.safetensors"
      - "--llm"
      - "./models/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      - "-v"
      - "--offload-to-cpu"
      - "--diffusion-fa"
      - "--steps"
      - "20"
    mode: "on_demand"
    exec_mode: "server"
    port: 1532
    model_type: "text-to-image"
    default_size: "1024x1024"
    startup_timeout: 180000
    generation_params:
      cfg_scale: 2.0
      sample_steps: 20
      sampling_method: "euler"
